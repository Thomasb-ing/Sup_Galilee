?rbinom
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,exp(-exp(2)/2))
rbinom(1,1,1
)
rbinom(1,1,1)
rbinom(1,1,1)
rbinom(1,1,1)
rbinom(1,1,0)
rbinom(1,1,0)
rbinom(1,1,0)
set.seed(2)
n=500
x1=rexp(n,1/5)
x2=floor(runif(n,18,100))
y=rep(0,n)
for(i in 1:n){
r=x1[i]
y[i]=rbinom(1,1,exp(-r/2))
}
datum=data.frame(x1=x1,x2=x2,y=y)
model <- glm(y ~ x1+x2, data = datum, family = binomial)
print(model)
summary(model)
model <- glm(y ~ x1+x2, data = datum, family = binomial)
print(model)
summary(model)
model <- glm(y ~ x1+x2, data = datum, family = binomial)
print(model)
summary(model)
model <- glm(y ~ x1, data = datum, family = binomial)
print(model)
model <- glm(y ~ x2, data = datum, family = binomial)
print(model)
n=1000
x1=rnorm(n,0,1)
x2=rnorm(n,0,4)
for(i in 1:n){
r=x1[i]
y[i]=rbinom(1,1,exp(-2+x[i]+x[2]+20*x[i]*y[i]/2))
}
data=data.frame(x1=x1,x2=x2,y=y)
n=1000
x1=rnorm(n,0,1)
x2=rnorm(n,0,4)
for(i in 1:n){
r=x1[i]
y[i]=rbinom(1,1,exp(-2+x1[i]+x2[2]+20*x1[i]*y2[i]/2))
}
data=data.frame(x1=x1,x2=x2,y=y)
n=1000
x1=rnorm(n,0,1)
x2=rnorm(n,0,4)
for(i in 1:n){
r=x1[i]
y[i]=rbinom(1,1,exp(-2+x1[i]+x2[2]+20*x1[i]*x2[i]/2))
}
data=data.frame(x1=x1,x2=x2,y=y)
n=1000
x1=rnorm(n,0,1)
x2=rnorm(n,0,4)
for(i in 1:n){
y[i]=rbinom(1,1,exp(-2+x1[i]+x2[2]+20*x1[i]*x2[i]))
}
data=data.frame(x1=x1,x2=x2,y=y)
model <- glm(y ~ ., data = data, family = binomial)
print(model)
model <- glm(y ~ x1, data = data, family = binomial)
print(model)
model <- glm(y ~ x2, data = data, family = binomial)
print(model)
model <- glm(y ~ ., data = data, family = binomial)
print(model)
?glm
x3=x2*x1
x3=x2*x1
data_x3=data.frame(x1=x1,x2=x2,x3,y=y)
model <- glm(y ~ ., data = data_x3, family = binomial)
print(model)
model <- glm(y ~ ., data = data, family = binomial)
print(model)
?t.willks
?willks.test
?willks.t
?test.willks
?test.wald
?test.walds
?test.wald
wald
summary(model)
?pchisq
chi2_2=0
pvalue=qchisq(0.95,2)
chi2_2=0
pvalue=qchisq(0.05,2)
chi2_2=0
pvalue=0.05
pvalue=qchisq(0.05,2,lower.tail=True)
chi2_2=0
pvalue=0.05
pvalue=qchisq(0.05,2,lower.tail=TRUE)
chi2_2=0
pvalue=0.05
pvalue=qchisq(1,2,lower.tail=TRUE)
chi2_2=0
pvalue=0.05
pvalue=qchisq(0.95,2,lower.tail=TRUE)
model <- glm(y ~ ., data = data, family = binomial)
print(model)
model.extract(null.deviance)
# Calculez le rapport de vraisemblance
llr <- 2 * (model$null.deviance - model$deviance)
df <- model$df.null - model$df.residual
p_value <- 1 - pchisq(llr, df)
# Interpréter le résultat
if(p_value < 0.05) {
cat("Le modèle logistique est significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
} else {
cat("Le modèle logistique n'est pas significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
}
data<-read.csv(file ='data_diabetis')
#Nombre de personne avec le diabete
sum(data["y"==1])
#Nombre de personne avec le diabete
sum(data$y)
#Nombre de personne avec le diabete (501)
sum(data$y)
summary(data)
#Nombre de personne avec le diabete (501)
sum(data$y)
drop(data,"y")
#Nombre de personne avec le diabete (501)
sum(data$y)
drop(data,("X"))
#Nombre de personne avec le diabete (501)
sum(data$y)
data$X<-NULL
model_diab<- glm(y ~ ., data = data, family = binomial)
print(model)
print(model_diab)
llr <- 2 * (model_diab$null.deviance - model_diab$deviance)
df <- model_diab$df.null - model_diab$df.residual
p_value <- 1 - pchisq(llr, df)
if(p_value < 0.05) {
cat("Le modèle logistique est significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
} else {
cat("Le modèle logistique n'est pas significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
}
summary(model_diab)
IMC=data$poids/((data$taille)/1000)^2
IMC=data$poids/((data$taille)/1000)^2
data=cbind(data,IMC)
model_diab<- glm(y ~ ., data = data, family = binomial)
print(model_diab)
llr <- 2 * (model_diab$null.deviance - model_diab$deviance)
df <- model_diab$df.null - model_diab$df.residual
p_value <- 1 - pchisq(llr, df)
if(p_value < 0.05) {
cat("Le modèle logistique est significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
} else {
cat("Le modèle logistique n'est pas significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
}
pchisq(45,1)
IMC=data$poids/((data$taille)/1000)^2
#data=cbind(data,IMC)
x3=data$poids/(data$taille)
data=cbind(data)
IMC=data$poids/((data$taille)/1000)^2
#data=cbind(data,IMC)
x3=data$poids/(data$taille)
data=cbind(data,x3)
model2_diab<- glm(y ~ ., data = data, family = binomial)
print(model_diab)
llr <- 2 * (model2_diab$null.deviance - model2_diab$deviance)
df <- model2_diab$df.null - model2_diab$df.residual
p_value <- 1 - pchisq(llr, df)
if(p_value < 0.05) {
cat("Le modèle logistique est significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
} else {
cat("Le modèle logistique n'est pas significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
}
heart_disease_dataset <- read.csv(file = "processed.cleveland.data", header = F)
#Prepare column names
names <- c("Age",
"Sex",
"Chest_Pain_Type",
"Resting_Blood_Pressure",
"Serum_Cholesterol",
"Fasting_Blood_Sugar",
"Resting_ECG",
"Max_Heart_Rate_Achieved",
"Exercise_Induced_Angina",
"ST_Depression_Exercise",
"Peak_Exercise_ST_Segment",
"Num_Major_Vessels_Flouro",
"Thalassemia",
"Diagnosis")
#Apply column names to the dataframe
colnames(heart_disease_dataset) <- names
#Glimpse data to verify new column names are in place, only with tidyverse library
#glimpse(heart_disease_dataset)
head(heart_disease_dataset)
summary(heart_disease_dataset)
heart_disease_dataset[heart_disease_dataset["Diagnosis"]!=0]=1
heart_disease_dataset[heart_disease_dataset["Diagnosis"]~=0]=1
heart_disease_dataset[heart_disease_dataset["Diagnosis"]!=0]=1
heart_disease_dataset["Diagnosis"]!=0
heart_disease_dataset$Diagnosis=heart_disease_dataset["Diagnosis"]!=0
library(caret)
heart_disease_dataset <- read.csv(file = "processed.cleveland.data", header = F)
#Prepare column names
names <- c("Age",
"Sex",
"Chest_Pain_Type",
"Resting_Blood_Pressure",
"Serum_Cholesterol",
"Fasting_Blood_Sugar",
"Resting_ECG",
"Max_Heart_Rate_Achieved",
"Exercise_Induced_Angina",
"ST_Depression_Exercise",
"Peak_Exercise_ST_Segment",
"Num_Major_Vessels_Flouro",
"Thalassemia",
"Diagnosis")
#Apply column names to the dataframe
colnames(heart_disease_dataset) <- names
#Glimpse data to verify new column names are in place, only with tidyverse library
#glimpse(heart_disease_dataset)
head(heart_disease_dataset)
summary(heart_disease_dataset)
```{r}
heart_disease_dataset$Diagnosis=heart_disease_dataset["Diagnosis"]!=0
library(caret)
createDataPartition(heart_dis)
?createDataPartition
library(caret)
createDataPartition(heart_disease_dataset,2)
library(caret)
p <- 0.7
data.A_index <- createDataPartition(data$response, p = p, list = FALSE)
data.A <- data[data.A_index,]
data.T <- data[-data.A_index,]
library(caret)
p <- 0.7
data.A_index <- createDataPartition(heart_disease_dataset, p = p, list = FALSE)
data.A <- heart_disease_dataset[data.A_index,]
data.T <- heart_disease_dataset[-data.A_index,]
library(caret)
p <- 0.7
data.A_index <- createDataPartition(heart_disease_dataset, time=1, list = FALSE)
data.A <- heart_disease_dataset[data.A_index,]
data.T <- heart_disease_dataset[-data.A_index,]
library(caret)
p <- 0.7
train_index <- sample(1:nrow(heart_disease_dataset), size = 0.7*nrow(heart_disease_dataset))
data.A <- heart_disease_dataset[train_index,]
data.T <- heart_disease_dataset[-train_index,]
model <- glm(Diagnosis ~ ., data = data.A, family = binomial)
summary(model)
model <- glm(Diagnosis ~ ., data = data.A, family = binomial)
print(model)
?print
cat("R2 de Marc Fadden =", 1-model$null.deviance/model$deviance, ")\n")
cat("R2 de Cox et Snell =", 1-model$null.deviance/model$deviance, ")\n")
cat("R2 de Nagelkerke =", 1-model$null.deviance/model$deviance, ")\n")
cat("R2 de Marc Fadden =", 1-model$deviance/model$null.deviance, ")\n")
cat("R2 de Cox et Snell =", 1-model$deviance/model$null.deviance, ")\n")
cat("R2 de Nagelkerke =", 1-model$deviance/model$null.deviance, ")\n")
n=length(data.A)
cat("R2 de Marc Fadden =", 1-model$deviance/model$null.deviance, ")\n")
cat("R2 de Cox et Snell =", 1-(model$deviance/model$null.deviance)^2/n, ")\n")
cat("R2 de Nagelkerke =", 1-model$deviance/model$null.deviance, ")\n")
n=length(data.A)
cat("R2 de Marc Fadden =", 1-model$deviance/model$null.deviance, ")\n")
cat("R2 de Cox et Snell =", 1-(model$deviance/model$null.deviance)^(2/n), ")\n")
cat("R2 de Nagelkerke =", 1-model$deviance/model$null.deviance, ")\n")
n=length(data.A)
cat("R2 de Marc Fadden =", 1-model$deviance/model$null.deviance, ")\n")
cat("R2 de Cox et Snell =", 1-(model$deviance/model$null.deviance)^(2/n), ")\n")
cat("R2 de Nagelkerke =", (1-(model$deviance/model$null.deviance)^(2/n))/(1-(model$deviance)^(2/n)), ")\n")
llr <- 2 * (model$null.deviance - model$deviance)
df <- model$df.null - model$df.residual
p_value <- 1 - pchisq(llr, df)
if(p_value < 0.05) {
cat("Le modèle logistique est significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
} else {
cat("Le modèle logistique n'est pas significativement meilleur que le modèle nul (p-value =", p_value, ")\n")
}
summary(model)
?predict
predict(model,data.T)
predict(model,subset(data.T, select=-c(Diagnosis)))
subset(data.T, select=-c(Diagnosis)
subset(data.T, select=-c(Diagnosis))
subset(data.T, select=-c(Diagnosis)))
subset(data.T, select=-c(Diagnosis))
predict(model,subset(data.T, select=-c(Diagnosis)),type = "response")
probabilities <- model %>% predict(subset(data.T, select=-c(Diagnosis)), type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
probabilities <- predict(model,subset(data.T, select=-c(Diagnosis)), type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
?table
probabilities.T <- predict(model,subset(data.T, select=-c(Diagnosis)), type = "response")
predicted.classes.T <- ifelse(probabilities > 0.5, "1", "0")
probabilities.A <- predict(model,subset(data.A, select=-c(Diagnosis)), type = "response")
predicted.classes.A <- ifelse(probabilities > 0.5, "1", "0")
table(predicted.classes.T,data.T$Diagnosis)
table(predicted.classes.T,data.T$Diagnosis)
table(predicted.classes.A,data.A$Diagnosis)
probabilities.T <- predict(model,subset(data.T, select=-c(Diagnosis)), type = "response")
predicted.classes.T <- ifelse(probabilities > 0.5, "1", "0")
probabilities.A <- predict(model,subset(data.A, select=-c(Diagnosis)), type = "response")
predicted.classes.A <- ifelse(probabilities > 0.5, "1", "0")
table(predicted.classes.T,data.T$Diagnosis)
table(predicted.classes.A,data.A$Diagnosis)
probabilities.T <- predict(model,subset(data.T, select=-c(Diagnosis)), type = "response")
predicted.classes.T <- ifelse(probabilities.T > 0.5, "1", "0")
probabilities.A <- predict(model,subset(data.A, select=-c(Diagnosis)), type = "response")
predicted.classes.A <- ifelse(probabilities.A > 0.5, "1", "0")
table(predicted.classes.T,data.T$Diagnosis)
table(predicted.classes.A,data.A$Diagnosis)
table(predicted.classes.T,data.T$Diagnosis)
cat("tx d'erreur de pour data.T",16/91,"\n")
table(predicted.classes.A,data.A$Diagnosis)
cat("tx d'erreur de pour data.T",28/212,"\n")
library(MASS)
step.model <- stepAIC(model,trace = FALSE)
coef(step.model)
probabilities.step.T <- predict(step.model, data.T, type = "response")
predicted.classes.step.T <- ifelse(probabilities.step.T > 0.5, "pos", "neg")
# Prediction accuracy
observed.classes.step.T <- data.T$Diagnosis
mean(predicted.classes.step.T == observed.classes.step.T)
probabilities.step.T <- predict(step.model, data.T, type = "response")
predicted.classes.step.T <- ifelse(probabilities.step.T > 0.5, "pos", "neg")
# Prediction accuracy
observed.classes.step.T <- data.T$Diagnosis
mean(predicted.classes.step.T == observed.classes.step.T)
table(predicted.classes.step.T,data.T$Diagnosis)
# Define training control
set.seed(123)
train.control <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# Train the model
model <- train(Diagnosis ~., data = heart_disease_dataset, method = "glm",
trControl = train.control)
# Summarize the results
print(model)
library(tidyverse)
library(caret)
# Define training control
set.seed(123)
train.control <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# Train the model
model <- train(Diagnosis ~., data = heart_disease_dataset, method = "glm",
trControl = train.control)
# Summarize the results
print(model)
?train
getModelInfo()
